{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import nltk\n",
    "import weaviate\n",
    "from weaviate.embedded import EmbeddedOptions\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from dotenv import load_dotenv\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text: list[str], tokenizer, model):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens).last_hidden_state\n",
    "    avg_pooled = output.mean(dim=1)\n",
    "    return avg_pooled.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunk(chunk, tokenizer, model):\n",
    "    tokens = tokenizer(chunk, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens).last_hidden_state\n",
    "    avg_pooled = output.mean(dim=1)\n",
    "    return {\"chunk\": chunk, \"embeddings\": avg_pooled.tolist()[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_chunked_text(chunked_text):\n",
    "    model_name = \"bert-base-uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        chunk_and_embeddings = list(executor.map(embed_chunk, chunked_text, [tokenizer]*len(chunked_text), [model]*len(chunked_text)))\n",
    "\n",
    "    return chunk_and_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, max_chunk_length, overlap=0):\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    step_size = max_chunk_length - overlap\n",
    "    num_chunks = (len(tokens) - overlap) // step_size + 1\n",
    "\n",
    "    chunks = [\n",
    "        tokens[i * step_size : i * step_size + max_chunk_length]\n",
    "        for i in range(num_chunks)\n",
    "    ]\n",
    "\n",
    "    chunked_text = [\" \".join(chunk) for chunk in chunks]\n",
    "\n",
    "    return chunked_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_text_list: list[str], chunk_threshold: int, token_overlap: int):\n",
    "    chunked_pdf_data = []\n",
    "    for text_index, text in enumerate(pdf_text_list):\n",
    "        chunked_text = chunk_text(text, chunk_threshold, token_overlap)\n",
    "        chunked_and_embedded_text = embed_chunked_text(chunked_text)\n",
    "        for chunk_index, chunk in enumerate(chunked_and_embedded_text):\n",
    "            chunked_pdf_data.append(\n",
    "                {\n",
    "                    \"chunk\": chunk[\"chunk\"],\n",
    "                    \"chunk_index\": chunk_index,\n",
    "                    \"embeddings\": chunk[\"embeddings\"],\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    return chunked_pdf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedded weaviate is already listening on port 8079\n"
     ]
    }
   ],
   "source": [
    "client = weaviate.Client(\n",
    "    embedded_options=EmbeddedOptions(),\n",
    "    additional_headers={\"X-OpenAI-Api-Key\": openai_api_key},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.schema.delete_class(\"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"testing_9cPyXMvVLpdB\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2023-12-18T22:02:11-05:00\",\"took\":66378}\n"
     ]
    }
   ],
   "source": [
    "class_name = \"Testing\"\n",
    "class_definition = {\n",
    "    \"class\": class_name,\n",
    "    \"vectorizer\": \"text2vec-openai\",\n",
    "}\n",
    "client.schema.create_class(class_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = [\n",
    "    \" A Simple PDF File \\n This is a small demonstration .pdf file - \\n just for use in the Virtual Mechanics tutorials. More text. And more \\n text. And more text. And more text. And more text. \\n And more text. And more text. And more text. And more text. And more \\n text. And more text. Boring, zzzzz. And more text. And more text. And \\n more text. And more text. And more text. And more text. And more text. \\n And more text. And more text. \\n And more text. And more text. And more text. And more text. And more \\n text. And more text. And more text. Even more. Continued on page 2 ...\\n\",\n",
    "    \" Simple PDF File 2 \\n ...continued from page 1. Yet more text. And more text. And more text. \\n And more text. And more text. And more text. And more text. And more \\n text. Oh, how boring typing this stuff. But not as boring as watching \\n paint dry. And more text. And more text. And more text. And more text. \\n Boring.  More, a little more text. The end, and just as well. \\n\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_embedded_text = process_pdf(text_list, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in chunked_embedded_text:\n",
    "    client.data_object.create({\"chunk\": data[\"chunk\"]}, \"Testing\", vector=data[\"embeddings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"what page\"\n",
    "vector = embed_text([text], tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.query.get(\n",
    "#     class_name=\"Chatpdf\", properties=[\"chunk\", \"file_name\"]\n",
    "# ).with_near_text({\"concepts\": [\"sample pdf\"]}).with_limit(3).do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class': 'Testing',\n",
       " 'invertedIndexConfig': {'bm25': {'b': 0.75, 'k1': 1.2},\n",
       "  'cleanupIntervalSeconds': 60,\n",
       "  'stopwords': {'additions': None, 'preset': 'en', 'removals': None}},\n",
       " 'moduleConfig': {'text2vec-openai': {'baseURL': 'https://api.openai.com',\n",
       "   'model': 'ada',\n",
       "   'modelVersion': '002',\n",
       "   'type': 'text',\n",
       "   'vectorizeClassName': True}},\n",
       " 'multiTenancyConfig': {'enabled': False},\n",
       " 'properties': [{'dataType': ['text'],\n",
       "   'description': \"This property was generated by Weaviate's auto-schema feature on Mon Dec 18 22:02:15 2023\",\n",
       "   'indexFilterable': True,\n",
       "   'indexSearchable': True,\n",
       "   'moduleConfig': {'text2vec-openai': {'skip': False,\n",
       "     'vectorizePropertyName': False}},\n",
       "   'name': 'chunk',\n",
       "   'tokenization': 'word'}],\n",
       " 'replicationConfig': {'factor': 1},\n",
       " 'shardingConfig': {'virtualPerPhysical': 128,\n",
       "  'desiredCount': 1,\n",
       "  'actualCount': 1,\n",
       "  'desiredVirtualCount': 128,\n",
       "  'actualVirtualCount': 128,\n",
       "  'key': '_id',\n",
       "  'strategy': 'hash',\n",
       "  'function': 'murmur3'},\n",
       " 'vectorIndexConfig': {'skip': False,\n",
       "  'cleanupIntervalSeconds': 300,\n",
       "  'maxConnections': 64,\n",
       "  'efConstruction': 128,\n",
       "  'ef': -1,\n",
       "  'dynamicEfMin': 100,\n",
       "  'dynamicEfMax': 500,\n",
       "  'dynamicEfFactor': 8,\n",
       "  'vectorCacheMaxObjects': 1000000000000,\n",
       "  'flatSearchCutoff': 40000,\n",
       "  'distance': 'cosine',\n",
       "  'pq': {'enabled': False,\n",
       "   'bitCompression': False,\n",
       "   'segments': 0,\n",
       "   'centroids': 256,\n",
       "   'trainingLimit': 100000,\n",
       "   'encoder': {'type': 'kmeans', 'distribution': 'log-normal'}}},\n",
       " 'vectorIndexType': 'hnsw',\n",
       " 'vectorizer': 'text2vec-openai'}"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "{\"action\":\"requests_total\",\"api\":\"rest\",\"class_name\":\"Chatpdf\",\"error\":\"update vector: connection to: OpenAI API failed with status: 429 error: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\",\"level\":\"error\",\"msg\":\"unexpected error\",\"query_type\":\"objects\",\"time\":\"2023-12-18T22:21:47-05:00\"}\n"
     ]
    }
   ],
   "source": [
    "client.schema.get(\"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'Get': {'Testing': [{'chunk': 'Continued on page 2 ...'},\n",
       "    {'chunk': 'continued from page 1 . Yet more text . And'},\n",
       "    {'chunk': 'text . Even more . Continued on page 2 ...'}]}}}"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query.get(class_name=\"Testing\", properties=[\"chunk\"]).with_hybrid(query=text, vector=vector).with_limit(3).do()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'Get': {'Testing': [{'chunk': '. More text . And more text . And more'},\n",
       "    {'chunk': 'little more text . The end , and just as'},\n",
       "    {'chunk': '. And more text . And more text . Boring'},\n",
       "    {'chunk': 'more text . And more text . Oh , how'},\n",
       "    {'chunk': 'end , and just as well .'},\n",
       "    {'chunk': 'text . Even more . Continued on page 2 ...'},\n",
       "    {'chunk': 'watching paint dry . And more text . And more'},\n",
       "    {'chunk': '. And more text . And more text . And'},\n",
       "    {'chunk': '. And more text . And more text . And'},\n",
       "    {'chunk': 'And more text . And more text . And more'},\n",
       "    {'chunk': 'text . Oh , how boring typing this stuff .'},\n",
       "    {'chunk': 'in the Virtual Mechanics tutorials . More text . And'},\n",
       "    {'chunk': 'more text . And more text . And more text'},\n",
       "    {'chunk': 'file - just for use in the Virtual Mechanics tutorials'},\n",
       "    {'chunk': 'text . And more text . And more text .'},\n",
       "    {'chunk': 'text . And more text . And more text .'},\n",
       "    {'chunk': '. And more text . And more text . And'},\n",
       "    {'chunk': 'more text . And more text . And more text'},\n",
       "    {'chunk': 'text . And more text . And more text .'},\n",
       "    {'chunk': 'boring typing this stuff . But not as boring as'},\n",
       "    {'chunk': 'And more text . Boring , zzzzz . And more'},\n",
       "    {'chunk': '. And more text . Boring . More , a'},\n",
       "    {'chunk': 'more text . And more text . Even more .'},\n",
       "    {'chunk': 'Continued on page 2 ...'},\n",
       "    {'chunk': 'text . And more text . And more text .'},\n",
       "    {'chunk': 'text . And more text . And more text .'},\n",
       "    {'chunk': 'more text . And more text . And more text'},\n",
       "    {'chunk': 'A Simple PDF File This is a small demonstration .pdf'},\n",
       "    {'chunk': 'more text . And more text . And more text'},\n",
       "    {'chunk': 'And more text . And more text . And more'},\n",
       "    {'chunk': 'more text . And more text . And more text'},\n",
       "    {'chunk': 'And more text . And more text . And more'},\n",
       "    {'chunk': 'Boring . More , a little more text . The'},\n",
       "    {'chunk': 'text . And more text . And more text .'},\n",
       "    {'chunk': 'Yet more text . And more text . And more'},\n",
       "    {'chunk': 'is a small demonstration .pdf file - just for use'},\n",
       "    {'chunk': 'And more text . And more text . And more'},\n",
       "    {'chunk': 'continued from page 1 . Yet more text . And'},\n",
       "    {'chunk': 'Simple PDF File 2 ... continued from page 1 .'},\n",
       "    {'chunk': 'And more text . And more text . And more'},\n",
       "    {'chunk': '. And more text . And more text . And'},\n",
       "    {'chunk': '. And more text . And more text . And'},\n",
       "    {'chunk': ', zzzzz . And more text . And more text'},\n",
       "    {'chunk': 'But not as boring as watching paint dry . And'},\n",
       "    {'chunk': 'text . And more text . And more text .'},\n",
       "    {'chunk': 'more text . And more text . And more text'}]}}}"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.query.get(\"Testing\", properties=[\"chunk\"]).do()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
